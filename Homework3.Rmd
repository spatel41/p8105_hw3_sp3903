---
title: "Homework 3"
output:
  html_document:
    theme: yeti
    highlight: haddock
---

### Loading Libraries
```{r}
library(tidyverse)
```

### Formatting plots
```{r}
knitr::opts_chunk$set(
  fig.width = 15,
  fig.asp = .6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.colour = "viridis")

sclae_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
library(p8105.datasets)
data("instacart")
```

### Instacart Dataset Descriptions

* The Instacart dataset includes `r length(instacart)` variables: `r variable.names(instacart)`.
* The dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns.
* The number of observations is `r count(instacart)`.
* The range of days since the prior order is (`r range(instacart$days_since_prior_order)`).
* The median number of items added to cart order is (`r median(instacart$add_to_cart_order)`).
* The total number of times an item was reordered is `r sum(instacart$reordered)`.

### Aisles: Count and Most Ordered

```{r}
instacart %>% 
  summarize(distinct_aisles = n_distinct(aisle))  
```

* There are 134 different aisles. 

### Creating a plot 
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = n, y = aisle)) +
  geom_point() +
  labs(
    title = "Number of Items Orders by Aisle",
    x = "Number of Items Sold",
    y = "Item") +
  scale_x_continuous(
    breaks = c(20000, 40000, 60000, 80000, 100000, 120000, 140000))
```
* The aisles where the most items are ordered from are 83 for fresh vegetables, 24 for fresh fruits, and 123 for packaged vegetables fruits. 

### Instacart: Cleaning and filter
```{r}
popular_items = instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4)
```

### Instacart: Table
```{r}
knitr::kable(head(popular_items[, 1:4]), "simple")
```

### Icecream: Cleaning and filtering
```{r}
applies_icecream = instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  mutate(
    order_dow = recode(order_dow,
                       "0" = "Sunday",
                       "1" = "Monday",
                       "2" = "Tuesday",
                       "3" = "Wednesday",
                       "4" = "Thursday",
                       "5" = "Friday",
                       "6" = "Saturday")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) 
```

### Icecream: Table
```{r}
knitr::kable(head(applies_icecream[, 1:8]), "simple")
```

# Problem 2
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

### Cleaning Data

```{r}
brfss_smart20102 = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  mutate(response = str_to_lower(response),
         response = recode(response,
                            "very good" = "very_good")) %>% 
  filter(topic == "Overall Health",
         response %in% c("excellent", "very_good", "good", "poor")) %>%
  mutate(response = factor(response, levels = c("excellent", "very_good", "good", "poor")))
```
                       
### 2002 states with 7 or more locations

```{r}
states_2002 = brfss_smart20102 %>% 
  filter(year == 2002) %>%
  count(locationabbr) %>% 
  filter(n >= 7)
```

* The following states observed 7 or more locations in 2002: `r (states_2002$locationabbr)`.

### 2010 states with 7 or more locations

```{r}
states_2010 = brfss_smart20102 %>% 
  filter(year == 2010) %>%
  count(locationabbr) %>% 
  filter(n >= 7)
```

* The following states observed 7 or more locations in 2010: `r (states_2010$locationabbr)`.

### String plot of excellent responses

```{r}
excellent = brfss_smart20102 %>% 
  filter(response == "excellent") %>% 
  group_by(locationabbr, year) %>% 
  mutate(average_data_value = mean(data_value)) %>% 
  select(year, average_data_value, locationabbr) %>% 
  ggplot(aes(x = year, y = average_data_value, group = locationabbr, color = locationabbr)) +
  geom_line(alpha = .6) +
    labs(
    title = "Data Values over Time in each State",
    x = "Year",
    y = "Average Data Value",
    colour = "States"
  ) +
  scale_x_continuous(
    breaks = c(2002:2010)) 

excellent
```

* The plot shows that the average data values tends to decrease over time for most states. The average data
values are typically around 22.5. 

### Distribution Plot

```{r}
plot_data = brfss_smart20102 %>% 
  filter(locationabbr == "NY") %>% 
  filter(year == c(2006,2010)) %>% 
  ggplot(aes(x = response, y = data_value, color = response)) + 
  geom_boxplot() + 
  facet_grid(. ~ year) + 
  labs(
    title = "Distribution of Data Values for Responses in New York",
    x = "Overall Health Response",
    y = "Data Values"
  )

plot_data
```

* The data values for for excellent, very good, and good are much higher than the data values for poor. 

# Problem 3

```{r}
accel = read_csv(file = "data/accel_data.csv")
```

### Accelerometer Dataset Cleaning 

```{r}
clean_accel = accel %>% 
  janitor::clean_names() %>% 
  mutate(week_day = ifelse(day %in% c("Saturday", "Sunday"), "weekday", "weekend")) %>% 
  select(week_day, everything()) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_day",
    values_to = "activity_counts")
```
 
### Accelerometer Dataset Description

* The Accelerometer dataset includes variables week_day, week, day_id, day, and activity.
* The dataset has `r nrow(accel)` rows and `r ncol(accel)` columns.
* The number of observations is `r count(accel)`.
* The mean amount of activity over the study period is `r mean(clean_accel$activity_counts)`.

### Aggregating Accelerometer Dataset 

```{r}
clean_accel2 = clean_accel %>%
  group_by(day_id, day) %>% 
  summarize(sum_activity = sum(activity_counts)) 
```

### Table of Activity Counter per Day
```{r}
knitr::kable(clean_accel2)
```

* While during the first half of the study period, the activity counts are high during weekends, the second half of the study period shows lower activity counts on the weekend. The counts per day typically stay around 400,000. The lowest levels of activity occur on day 24 and 31.  

### Plot of 24-hour activity time 

```{r}
ggplot(clean_accel, aes(x = day_id, y = activity_counts, color = day)) +
  geom_point() +
  labs(
    title = "Activity Counts per Day",
    x = "Day ID",
    y = "Activity Count",
    colour = "Day of the Week" 
  ) +
  scale_x_continuous(
    breaks = c(0:36))
```

* The person is more active in the morning than later in the day where activity tapers off. The person is often very active on Saterday's. 
